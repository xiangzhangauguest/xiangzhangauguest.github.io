---
title: "Feature Selection"
layout: post
category: [人生经验]
tags: [mysql]
excerpt: "Feature selection in machine learning."
---

# 综述

1、考虑一个因素能否作为特征，需要看这个因素是否有区分性。

2、特征太多，有可能导致有些特征对应的训练样本不足，那么会使这些特征的训练权重有偏差。另外，特征太多容易过拟合，导致模型泛化能力变差。（比如在广告中queryLength＝100这个特征，特征本身是有意义的，但是可能这个特征对应的query并不是topquery也就是属于长尾流量对应的部分，所以对应的训练样本不足，导致最后训练出来的分不准。［https://blog.csdn.net/xietingcandice/article/details/46462825］）

3、选中了特征，还需要注意特征的选择方式，例如，如果单独把年龄作为一个特征，最终能训练出来啥吗？因为年龄相加相减是没有意义的，所以只能把每个年龄做为一个特征，但是光这样可以了吗？怎么用特征，是广告算法工程师的一个大课题。（https://blog.csdn.net/mytestmy/article/details/19088827）

4、想到了特征，就要验证和进行判断。 验证特征的办法多，有直接观察ctr，卡方检验，单特征AUC等。直接观察ctr是个很有效的方法，如根据投放记录，化妆品的广告在女性上面的点击率就比在男性上面的点击率高很多，说明性别这个特征在化妆品行业是有预测能力的；又如体育用品的广告在男性上面的点击率也比女性高，说明性别这个特征在体育行业也是有预测能力的，经过多个行业的验证，就认为性别这个特征可以用了。 年龄这个特征的评估类型，主要是观察一个广告在不同年龄段的点击率是否有区别，再观察不同广告的点击率在不同年龄段的分布是否不一样，如果都有区别，说明年龄这个特征就可以用了。 在实际的使用中发现，性别这个特征比较有效，手机平台这个特征也比较有效，地域和年龄这两个特征有一定效果，但没有前两个那么明显，跟他们的使用方式可能有关，还需要进一步挖掘。 同时，实际使用中也发现，广告反馈ctr这个特征也很有效，这个特征的意思就是当前的广告正在投放，已经投放了一部分了，这部分的点击率基本可以认为是这个广告的点击率了，也可以认为是这个广告的质量的一个体现，用来预估一个流量的ctr是很有效的。（https://blog.csdn.net/mytestmy/article/details/19088827）



1. 计算一个特征与响应变量的相关性：计算皮尔逊系数或者互信息系数。
2. l1做特征选择。注意l1没有选到的特征不一定不重要，原因是可能两个高相关性的特征可能只保留了一个，如果要确定哪个特征重要应该再通过l2正则检验。
3. 训练能够对特征打分的模型，如：LR和RF。通过打分获得相关性后再训练最终模型。

# Filter

过滤法，按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。

皮尔逊系数只能衡量相关性，而互信系系数能很好的度量各种相关性

## 方差选择法

计算各个特征的方差，然后根据阈值，选择方差大于阈值的特征。

```py
from sklearn.feature_selection import VarianceThreshold

#方差选择法，返回值为特征选择后的数据
#参数threshold为方差的阈值
VarianceThreshold(threshold=3).fit_transform(iris.data)

作者：城东
链接：https://www.zhihu.com/question/28641663/answer/110165221
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
```

## 相关系数法

计算各个特征对目标值的相关系数以及相关系数的P值。

## 卡方检验

卡方检验是检验定性自变量对定性因变量的相关性。这个统计量的含义就是自变量对因变量的相关性。

## 互信息法

互信息也是评价定性自变量对定性因变量的相关性的。

# Wrapper

## 递归特征消除法

递归消除特征法使用一个基模型来进行多轮训练，每轮训练后，消除若干权值系数的特征，再基于新的特征集进行下一轮训练。

# Embedded

## 
